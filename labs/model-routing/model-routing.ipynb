{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## Model routing lab\n",
    "![flow](../../images/model-routing.gif)\n",
    "\n",
    "Playground to try routing to a backend based on Azure OpenAI model and version.\n",
    "\n",
    "### TOC\n",
    "- [0Ô∏è‚É£ Initialize notebook variables](#0)\n",
    "- [1Ô∏è‚É£ Create the Azure Resource Group](#1)\n",
    "- [2Ô∏è‚É£ Create deployment using ü¶æ Bicep](#2)\n",
    "- [3Ô∏è‚É£ Get the deployment outputs](#3)\n",
    "- [üß™ Test the API using a direct HTTP call](#requests)\n",
    "- [üß™ Test the API using the Azure OpenAI Python SDK](#sdk)\n",
    "- [üóëÔ∏è Clean up resources](#clean)\n",
    "\n",
    "### Backlog\n",
    "- Improve the notebook\n",
    "\n",
    "### Prerequisites\n",
    "- [Python 3.8 or later version](https://www.python.org/) installed\n",
    "- [Pandas Library](https://pandas.pydata.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli) installed\n",
    "- [An Azure Subscription](https://azure.microsoft.com/en-us/free/) with Contributor permissions\n",
    "- [Access granted to Azure OpenAI](https://aka.ms/oai/access)\n",
    "- [Sign in to Azure with Azure CLI](https://learn.microsoft.com/en-us/cli/azure/authenticate-azure-cli-interactively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/en-us/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "index = '1'  # Set a matching value here and in clean-up-resources.ipynb if you want separate instances of the lab. This is helpful when tearing down resources and mitigating API Management's soft delete.\n",
    "resource_group_name = f\"lab-{deployment_name}{index}\" # change the name to match your naming style\n",
    "resource_group_location = \"westeurope\"\n",
    "\n",
    "# Define three OpenAI model and version combinations\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-35\n",
    "# Please note that availability of models and versions is variable and that you may need to adjust the model and version names to match the available models and versions in your Azure subscription.\n",
    "# For this lab, we are using the following combinations based on PayGo availability on June 21, 2024:\n",
    "#\n",
    "#   1) GPT-3.5 Turbo 1106: France Central, Sweden Central\n",
    "#   2) GPT-3.5 Turbo 0125: North Central US, South Central US\n",
    "#   3) GPT-4o 2024-05-13: East US, West US\n",
    "\n",
    "openai_model_gpt_35_turbo_0125 = { \"name\": \"gpt-35-turbo\", \"version\": \"0125\" }\n",
    "openai_model_gpt_35_turbo_1106 = { \"name\": \"gpt-35-turbo\", \"version\": \"1106\" }\n",
    "openai_model_gpt_4o_20240513 = { \"name\": \"gpt-4o\", \"version\": \"2024-05-13\" }\n",
    "\n",
    "openai_model_1_name = \"gpt-35-turbo\"\n",
    "openai_model_1_version = \"1106\"\n",
    "openai_deployment_1_name = f\"{openai_model_1_name}-{openai_model_1_version}\"\n",
    "openai_resources_1 = [ {\"name\": \"oai-francecentral\", \"location\": \"francecentral\"}, {\"name\": \"oai-swedencentral\", \"location\": \"swedencentral\"} ]\n",
    "\n",
    "openai_model_2_name = \"gpt-35-turbo\"\n",
    "openai_model_2_version = \"0125\"\n",
    "openai_deployment_2_name = f\"{openai_model_2_name}-{openai_model_2_version}\"\n",
    "openai_resources_2 = [ {\"name\": \"oai-northcentralus\", \"location\": \"northcentralus\"}, {\"name\": \"oai-southcentralus\", \"location\": \"southcentralus\"} ]\n",
    "\n",
    "openai_model_3_name = \"gpt-4o\"\n",
    "openai_model_3_version = \"2024-05-13\"\n",
    "openai_deployment_3_name = f\"{openai_model_3_name}-{openai_model_3_version}\"\n",
    "openai_resources_3 = [ {\"name\": \"oai-eastus\", \"location\": \"eastus\"}, {\"name\": \"oai-westus\", \"location\": \"westus\"} ]\n",
    "\n",
    "# Define Azure OpenAI resources\n",
    "openai_resources_sku = \"S0\"\n",
    "openai_api_version = \"2024-02-01\"\n",
    "openai_specification_url='https://raw.githubusercontent.com/Azure/azure-rest-api-specs/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/stable/' + openai_api_version + '/inference.json'\n",
    "\n",
    "# Define Azure API Management\n",
    "apim_resource_name = \"apim\"\n",
    "apim_resource_location = \"westeurope\"\n",
    "apim_resource_sku = \"Basicv2\"\n",
    "\n",
    "# Define the Azure OpenAI backends and backend pools per Azure OpenAI model and version\n",
    "openai_backend_pool_1 = f\"oai-backend-pool-{openai_deployment_1_name}\"\n",
    "openai_backend_pool_2 = f\"oai-backend-pool-{openai_deployment_2_name}\"\n",
    "openai_backend_pool_3 = f\"oai-backend-pool-{openai_deployment_3_name}\"\n",
    "\n",
    "log_analytics_name = \"workspace\"\n",
    "app_insights_name = 'insights'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Create the Azure Resource Group\n",
    "All resources deployed in this lab will be created in the specified resource group. Skip this step if you want to use an existing resource group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "resource_group_stdout = ! az group create --name {resource_group_name} --location {resource_group_location} \n",
    "\n",
    "if resource_group_stdout.n.startswith(\"ERROR\"):\n",
    "    print(resource_group_stdout)\n",
    "else:\n",
    "    print(\"‚úÖ Azure Resource Group \", resource_group_name, \" created ‚åö \", datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(openai_resources_1) > 0:\n",
    "    backend_id_1 = openai_backend_pool_1 if len(openai_resources_1) > 1 else openai_resources_1[0].get(\"name\")\n",
    "if len(openai_resources_2) > 0:\n",
    "    backend_id_2 = openai_backend_pool_2 if len(openai_resources_2) > 1 else openai_resources_2[0].get(\"name\")\n",
    "if len(openai_resources_3) > 0:\n",
    "    backend_id_3 = openai_backend_pool_3 if len(openai_resources_3) > 1 else openai_resources_3[0].get(\"name\")\n",
    "\n",
    "with open(\"policy.xml\", 'r') as policy_xml_file:\n",
    "    policy_template_xml = policy_xml_file.read()\n",
    "    policy_xml = policy_template_xml.replace(\"{backend-id-1}\", backend_id_1).replace(\"{backend-id-2}\", backend_id_2).replace(\"{backend-id-3}\", backend_id_3)\n",
    "    policy_xml_file.close()\n",
    "open(\"policy.xml\", 'w').write(policy_xml)\n",
    "\n",
    "bicep_parameters = {\n",
    "  \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "  \"contentVersion\": \"1.0.0.0\",\n",
    "  \"parameters\": {\n",
    "    \"openAIBackendPoolName_1\": { \"value\": openai_backend_pool_1 },\n",
    "    \"openAIBackendPoolName_2\": { \"value\": openai_backend_pool_2 },\n",
    "    \"openAIBackendPoolName_3\": { \"value\": openai_backend_pool_3 },\n",
    "    \"openAIConfig_1\": { \"value\": openai_resources_1 },\n",
    "    \"openAIConfig_2\": { \"value\": openai_resources_2 },\n",
    "    \"openAIConfig_3\": { \"value\": openai_resources_3 },\n",
    "    \"openAIDeploymentName_1\": { \"value\": openai_deployment_1_name },\n",
    "    \"openAIDeploymentName_2\": { \"value\": openai_deployment_2_name },\n",
    "    \"openAIDeploymentName_3\": { \"value\": openai_deployment_3_name },\n",
    "    \"openAISku\": { \"value\": openai_resources_sku },\n",
    "    \"openAIModelName_1\": { \"value\": openai_model_1_name },\n",
    "    \"openAIModelName_2\": { \"value\": openai_model_2_name },\n",
    "    \"openAIModelName_3\": { \"value\": openai_model_3_name },\n",
    "    \"openAIModelVersion_1\": { \"value\": openai_model_1_version },\n",
    "    \"openAIModelVersion_2\": { \"value\": openai_model_2_version },\n",
    "    \"openAIModelVersion_3\": { \"value\": openai_model_3_version },\n",
    "    \"openAIModelCapacity\": { \"value\": 2 },\n",
    "    \"openAIAPISpecURL\": { \"value\": openai_specification_url },\n",
    "    \"apimResourceName\": { \"value\": apim_resource_name},\n",
    "    \"apimResourceLocation\": { \"value\": apim_resource_location},\n",
    "    \"apimSku\": { \"value\": apim_resource_sku},\n",
    "    \"logAnalyticsName\": { \"value\": log_analytics_name },\n",
    "    \"applicationInsightsName\": { \"value\": app_insights_name },\n",
    "    \"index\": { \"value\": index}\n",
    "  }\n",
    "}\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "! az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file \"main.bicep\" --parameters \"params.json\"\n",
    "\n",
    "open(\"policy.xml\", 'w').write(policy_template_xml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "We are now at the stage where we only need to retrieve the gateway URL and the subscription before we are ready for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâüèª API Gateway URL:  https://apim-qdp4k6fhzarv4.azure-api.net\n",
      "üëâüèª Workspace ID:  f71c1365-1228-4263-8118-40404d5f1ac3\n",
      "üëâüèª App ID:  46a7cd8e-e5a2-4585-94bb-65510d239a34\n"
     ]
    }
   ],
   "source": [
    "# type: ignore\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimSubscriptionKey.value -o tsv\n",
    "apim_subscription_key = deployment_stdout.n\n",
    "\n",
    "# type: ignore\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimResourceGatewayURL.value -o tsv\n",
    "apim_resource_gateway_url = deployment_stdout.n\n",
    "print(\"üëâüèª API Gateway URL: \", apim_resource_gateway_url)\n",
    "\n",
    "# type: ignore\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.logAnalyticsWorkspaceId.value -o tsv\n",
    "workspace_id = deployment_stdout.n\n",
    "print(\"üëâüèª Workspace ID: \", workspace_id)\n",
    "\n",
    "# type: ignore\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.applicationInsightsAppId.value -o tsv\n",
    "app_id = deployment_stdout.n\n",
    "print(\"üëâüèª App ID: \", app_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### üß™ Test the API using a direct HTTP call\n",
    "Requests is an elegant and simple HTTP library for Python that will be used here to make raw API requests and inspect the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñ∂Ô∏è Run: 1/10 for deployment gpt-35-turbo-1106\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-1106/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.83 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Length': '918', 'Content-Type': 'application/json', 'Date': 'Fri, 26 Jul 2024 17:49:43 GMT', 'Access-Control-Allow-Origin': '*', 'Cache-Control': 'no-cache, must-revalidate', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '8d6ff6f5-3c0b-49ab-a9ff-d1f04fcbf671', 'X-Content-Type-Options': 'nosniff', 'x-ms-region': 'Sweden Central', 'x-ratelimit-remaining-requests': '1', 'x-ratelimit-remaining-tokens': '1340', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'ab7e32a3-a186-45a9-a4ff-ddf24d936c59', 'x-ms-client-request-id': 'Not-Set', 'azureml-model-session': 'd111-20240710164001', 'remaining-tokens': '1839', 'consumed-tokens': '50', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: Sweden Central\n",
      "\n",
      "response:  Oh, I would, but that sounds like too much effort. Maybe just glance at a clock?\n",
      "\n",
      "‚ñ∂Ô∏è Run: 2/10 for deployment gpt-35-turbo-1106\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-1106/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.43 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Length': '927', 'Content-Type': 'application/json', 'Date': 'Fri, 26 Jul 2024 17:49:45 GMT', 'Access-Control-Allow-Origin': '*', 'Cache-Control': 'no-cache, must-revalidate', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '3b67523d-99ab-42bf-824d-98178205f6a7', 'X-Content-Type-Options': 'nosniff', 'x-ms-region': 'France Central', 'x-ratelimit-remaining-requests': '1', 'x-ratelimit-remaining-tokens': '680', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '8f725079-5bae-489d-a8a0-1bc65de29b79', 'x-ms-client-request-id': 'Not-Set', 'azureml-model-session': 'd002-20240713062420', 'remaining-tokens': '1842', 'consumed-tokens': '53', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: France Central\n",
      "\n",
      "response:  Oh, I'm just a virtual assistant, not a clock. Maybe you should ask a clock for the time.\n",
      "\n",
      "‚ñ∂Ô∏è Run: 3/10 for deployment gpt-35-turbo-1106\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-1106/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.36 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Length': '912', 'Content-Type': 'application/json', 'Date': 'Fri, 26 Jul 2024 17:49:46 GMT', 'Access-Control-Allow-Origin': '*', 'Cache-Control': 'no-cache, must-revalidate', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '56997a8a-a751-4d70-ac85-cd332fe725b6', 'X-Content-Type-Options': 'nosniff', 'x-ms-region': 'Sweden Central', 'x-ratelimit-remaining-requests': '0', 'x-ratelimit-remaining-tokens': '680', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'b1c84278-dfca-41b7-8d86-f66bb9789037', 'x-ms-client-request-id': 'Not-Set', 'azureml-model-session': 'd103-20240606191632', 'remaining-tokens': '1795', 'consumed-tokens': '47', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: Sweden Central\n",
      "\n",
      "response:  Oh, sure, because you couldn't possibly have figured that out on your own.\n",
      "\n",
      "‚ñ∂Ô∏è Run: 4/10 for deployment gpt-35-turbo-1106\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-1106/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.41 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Length': '893', 'Content-Type': 'application/json', 'Date': 'Fri, 26 Jul 2024 17:49:47 GMT', 'Access-Control-Allow-Origin': '*', 'Cache-Control': 'no-cache, must-revalidate', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'aa1d53f7-f705-4b98-adb7-9956309c13aa', 'X-Content-Type-Options': 'nosniff', 'x-ms-region': 'France Central', 'x-ratelimit-remaining-requests': '0', 'x-ratelimit-remaining-tokens': '20', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '1c90bf4e-7560-4fac-bb90-33e45a9110e2', 'x-ms-client-request-id': 'Not-Set', 'azureml-model-session': 'd001-20240713054510', 'remaining-tokens': '1748', 'consumed-tokens': '47', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: France Central\n",
      "\n",
      "response:  Oh, I would love to, but sorry, I can't help with that.\n",
      "\n",
      "‚ñ∂Ô∏è Run: 5/10 for deployment gpt-35-turbo-1106\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-1106/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.19 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "Response headers: {'Content-Length': '0', 'Date': 'Fri, 26 Jul 2024 17:49:49 GMT', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: None\n",
      "\n",
      "‚ñ∂Ô∏è Run: 6/10 for deployment gpt-35-turbo-1106\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-1106/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.34 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Length': '928', 'Content-Type': 'application/json', 'Date': 'Fri, 26 Jul 2024 17:49:54 GMT', 'Access-Control-Allow-Origin': '*', 'Cache-Control': 'no-cache, must-revalidate', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'bbf09c53-36ca-4829-bb6f-4d091614366a', 'X-Content-Type-Options': 'nosniff', 'x-ms-region': 'Sweden Central', 'x-ratelimit-remaining-requests': '0', 'x-ratelimit-remaining-tokens': '20', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '18d03c34-6f00-476d-8f59-e3faf63c1291', 'x-ms-client-request-id': 'Not-Set', 'azureml-model-session': 'd108-20240606233657', 'remaining-tokens': '1727', 'consumed-tokens': '46', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: Sweden Central\n",
      "\n",
      "response:  I would, but telling time is too difficult for my highly advanced artificial intelligence.\n",
      "\n",
      "‚ñ∂Ô∏è Run: 7/10 for deployment gpt-35-turbo-1106\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-1106/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.49 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Length': '940', 'Content-Type': 'application/json', 'Date': 'Fri, 26 Jul 2024 17:49:55 GMT', 'Access-Control-Allow-Origin': '*', 'Cache-Control': 'no-cache, must-revalidate', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '4caf696c-257a-4115-b42a-ae443c0c9022', 'X-Content-Type-Options': 'nosniff', 'x-ms-region': 'France Central', 'x-ratelimit-remaining-requests': '0', 'x-ratelimit-remaining-tokens': '20', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'dd38e985-6ccd-4f9f-9233-9943de463378', 'x-ms-client-request-id': 'Not-Set', 'azureml-model-session': 'd003-20240713065924', 'remaining-tokens': '1671', 'consumed-tokens': '56', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: France Central\n",
      "\n",
      "response:  Sure, I can tell you the time, but I think you might have a clock on your device that can do that too.\n",
      "\n",
      "‚ñ∂Ô∏è Run: 8/10 for deployment gpt-35-turbo-1106\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-1106/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.19 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "Response headers: {'Content-Length': '0', 'Date': 'Fri, 26 Jul 2024 17:49:57 GMT', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: None\n",
      "\n",
      "‚ñ∂Ô∏è Run: 9/10 for deployment gpt-35-turbo-1106\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-1106/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.20 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "Response headers: {'Content-Length': '0', 'Date': 'Fri, 26 Jul 2024 17:50:01 GMT', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: None\n",
      "\n",
      "‚ñ∂Ô∏è Run: 10/10 for deployment gpt-35-turbo-1106\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-1106/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.13 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "Response headers: {'Content-Length': '0', 'Date': 'Fri, 26 Jul 2024 17:50:07 GMT', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: None\n",
      "\n",
      "‚ñ∂Ô∏è Run: 1/10 for deployment gpt-35-turbo-0125\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-0125/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.63 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Length': '940', 'Content-Type': 'application/json', 'Date': 'Fri, 26 Jul 2024 17:50:13 GMT', 'Access-Control-Allow-Origin': '*', 'Cache-Control': 'no-cache, must-revalidate', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'e2a54128-794d-4f5e-9f14-0da45a4295bf', 'X-Content-Type-Options': 'nosniff', 'x-ms-region': 'North Central US', 'x-ratelimit-remaining-requests': '1', 'x-ratelimit-remaining-tokens': '1340', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '17b45626-da63-49ec-b6cb-ea0a6bcddc62', 'azureml-model-session': 'd014-20240713112355', 'x-envoy-upstream-service-time': '365', 'x-ms-client-request-id': 'Not-Set', 'remaining-tokens': '1524', 'consumed-tokens': '57', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: North Central US\n",
      "\n",
      "response:  Oh, sure, I'd be happy to tell you the time... if only you had a device that could display it for you.\n",
      "\n",
      "‚ñ∂Ô∏è Run: 2/10 for deployment gpt-35-turbo-0125\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-0125/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.57 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Length': '923', 'Content-Type': 'application/json', 'Date': 'Fri, 26 Jul 2024 17:50:14 GMT', 'Access-Control-Allow-Origin': '*', 'Cache-Control': 'no-cache, must-revalidate', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '0e0ff0f7-5eb5-482f-a27d-bad9b9e6b457', 'X-Content-Type-Options': 'nosniff', 'x-ms-region': 'South Central US', 'x-ratelimit-remaining-requests': '1', 'x-ratelimit-remaining-tokens': '1340', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '37783cb9-8022-4ac5-8fec-e8a54cab6104', 'azureml-model-session': 'd052-20240605133835', 'x-envoy-upstream-service-time': '294', 'x-ms-client-request-id': 'Not-Set', 'remaining-tokens': '1475', 'consumed-tokens': '49', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: South Central US\n",
      "\n",
      "response:  Oh, sorry, I forgot to bring my watch that I totally own to this digital interaction.\n",
      "\n",
      "‚ñ∂Ô∏è Run: 3/10 for deployment gpt-35-turbo-0125\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-0125/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.92 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Length': '992', 'Content-Type': 'application/json', 'Date': 'Fri, 26 Jul 2024 17:50:16 GMT', 'Access-Control-Allow-Origin': '*', 'Cache-Control': 'no-cache, must-revalidate', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '1081cd55-16f9-491f-b815-233ee7145c2e', 'X-Content-Type-Options': 'nosniff', 'x-ms-region': 'North Central US', 'x-ratelimit-remaining-requests': '0', 'x-ratelimit-remaining-tokens': '680', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'aa90caf0-dbbb-45f9-a088-46cfd5af1535', 'azureml-model-session': 'd013-20240713105021', 'x-envoy-upstream-service-time': '665', 'x-ms-client-request-id': 'Not-Set', 'remaining-tokens': '1409', 'consumed-tokens': '66', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: North Central US\n",
      "\n",
      "response:  Oh sure, let me just consult my sundial and my hourglass to give you the precise time. Oh wait, you probably have a device that can tell you that already.\n",
      "\n",
      "‚ñ∂Ô∏è Run: 4/10 for deployment gpt-35-turbo-0125\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-0125/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.69 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Length': '943', 'Content-Type': 'application/json', 'Date': 'Fri, 26 Jul 2024 17:50:18 GMT', 'Access-Control-Allow-Origin': '*', 'Cache-Control': 'no-cache, must-revalidate', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '3383619e-8284-4eb0-b882-4bd463d45109', 'X-Content-Type-Options': 'nosniff', 'x-ms-region': 'South Central US', 'x-ratelimit-remaining-requests': '0', 'x-ratelimit-remaining-tokens': '680', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '9056612a-bc59-4f45-a175-866acf9d0fcc', 'azureml-model-session': 'd049-20240605110030', 'x-envoy-upstream-service-time': '409', 'x-ms-client-request-id': 'Not-Set', 'remaining-tokens': '1352', 'consumed-tokens': '57', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: South Central US\n",
      "\n",
      "response:  Oh, I would love to help you with that, but unfortunately, my clock is stuck on \"I don't care o'clock.\"\n",
      "\n",
      "‚ñ∂Ô∏è Run: 5/10 for deployment gpt-35-turbo-0125\n",
      "APIM Subscription Key: e29c474acb7e403792d027cf9a08e4ea\n",
      "url:  https://apim-qdp4k6fhzarv4.azure-api.net/openai/deployments/gpt-35-turbo-0125/chat/completions?api-version=2024-02-01\n",
      "‚åö 0.39 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "Response headers: {'Content-Length': '0', 'Date': 'Fri, 26 Jul 2024 17:50:19 GMT', 'Request-Context': 'appId=cid-v1:46a7cd8e-e5a2-4585-94bb-65510d239a34'}\n",
      "x-ms-region: None\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "runs = 10\n",
    "sleep_time_ms = 1000\n",
    "\n",
    "# Initialize a session for connection pooling\n",
    "session = requests.Session()\n",
    "\n",
    "def make_api_request(deployment_name, openai_resources, apim_subscription_key, apim_resource_gateway_url, openai_api_version, sleep_time_ms):\n",
    "    if len(openai_resources) > 0:\n",
    "        print(\"APIM Subscription Key:\", apim_subscription_key)\n",
    "        \n",
    "        messages = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "            ]\n",
    "        }\n",
    "        url = f\"{apim_resource_gateway_url}/openai/deployments/{deployment_name}/chat/completions?api-version={openai_api_version}\"\n",
    "        print(\"url: \", url)\n",
    "\n",
    "        start_time = time.time()\n",
    "        response = session.post(url, headers={'api-key': apim_subscription_key}, json=messages)\n",
    "        response_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"‚åö {response_time:.2f} seconds\")\n",
    "        # Check the response status code and apply formatting\n",
    "        if 200 <= response.status_code < 300:\n",
    "            status_code_str = '\\x1b[1;32m' + str(response.status_code) + \" - \" + response.reason + '\\x1b[0m'  # Bold and green\n",
    "        elif response.status_code >= 400:\n",
    "            status_code_str = '\\x1b[1;31m' + str(response.status_code) + \" - \" + response.reason + '\\x1b[0m'  # Bold and red\n",
    "        else:\n",
    "            status_code_str = str(response.status_code)  # No formatting\n",
    "\n",
    "        # Print the response status with the appropriate formatting\n",
    "        print(\"Response status:\", status_code_str)\n",
    "    \n",
    "        print(\"Response headers:\", response.headers)\n",
    "        print(\"x-ms-region:\", response.headers.get(\"x-ms-region\"))  # Useful to determine the region of the backend\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(\"\\nresponse: \", data.get(\"choices\")[0].get(\"message\").get(\"content\"))\n",
    "            time.sleep(sleep_time_ms / 1000)\n",
    "        elif response.status_code == 503:\n",
    "            time.sleep(sleep_time_ms * 5 / 1000)\n",
    "        else:\n",
    "            if response.text:\n",
    "                print(response.text)\n",
    "        \n",
    "\n",
    "# Define your deployments and resources\n",
    "deployments = [\n",
    "    {\"name\": openai_deployment_1_name, \"resources\": openai_resources_1},    # GPT-3.5 Turbo 1106\n",
    "    {\"name\": openai_deployment_2_name, \"resources\": openai_resources_2},    # GPT-3.5 Turbo 0125\n",
    "    {\"name\": openai_deployment_3_name, \"resources\": openai_resources_3},    # GPT-4o 2024-05-13\n",
    "]\n",
    "\n",
    "apim_subscription_keys = [\n",
    "    'e29c474acb7e403792d027cf9a08e4ea',\n",
    "    #'e5765d85094341e5aae9865c0c7794ab',\n",
    "    #'00eec5eb3e67490f83c2cd9f8a548959'\n",
    "]\n",
    "\n",
    "# Loop through each deployment and make the API request\n",
    "for deployment in deployments:\n",
    "    for i in range(runs):\n",
    "        print(f\"\\n‚ñ∂Ô∏è Run: {i+1}/{runs} for deployment {deployment['name']}\")\n",
    "        make_api_request(deployment['name'], deployment['resources'], apim_subscription_keys[i % len(apim_subscription_keys)], apim_resource_gateway_url, openai_api_version, sleep_time_ms)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the API using the Azure OpenAI Python SDK\n",
    "OpenAPI provides a widely used [Python library](https://github.com/openai/openai-python). The library includes type definitions for all request params and response fields. The goal of this test is to assert that APIM can seamlessly proxy requests to OpenAI without disrupting its functionality.\n",
    "- Note: run ```pip install openai``` in a terminal before executing this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "runs = 2\n",
    "sleep_time_ms = 1000\n",
    "\n",
    "def make_openaisdk_request(deployment_name, openai_resources, apim_subscription_key, apim_resource_gateway_url, openai_api_version, sleep_time_ms):\n",
    "    from openai import AzureOpenAI\n",
    "    if len(openai_resources) > 0:\n",
    "        messages = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "            ]\n",
    "        }\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=apim_resource_gateway_url,\n",
    "            api_key=apim_subscription_key,\n",
    "            api_version=openai_api_version\n",
    "        )\n",
    "        response = client.chat.completions.create(model=openai_deployment_1_name, messages=messages)\n",
    "        print(response.choices[0].message.content)\n",
    "        time.sleep(sleep_time_ms/1000)\n",
    "\n",
    "# Define your deployments and resources\n",
    "deployments = [\n",
    "    {\"name\": openai_deployment_1_name, \"resources\": openai_resources_1},    # GPT-3.5 Turbo 1106\n",
    "    {\"name\": openai_deployment_2_name, \"resources\": openai_resources_2},    # GPT-3.5 Turbo 0125\n",
    "    {\"name\": openai_deployment_3_name, \"resources\": openai_resources_3},    # GPT-4o 2024-05-13\n",
    "]\n",
    "\n",
    "# Loop through each deployment and make the API request\n",
    "for deployment in deployments:\n",
    "    for i in range(runs):\n",
    "        print(f\"\\n‚ñ∂Ô∏è Run: {i+1} for deployment {deployment['name']}\")\n",
    "        make_api_request(deployment['name'], deployment['resources'], apim_subscription_key, apim_resource_gateway_url, openai_api_version, sleep_time_ms)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='portal'></a>\n",
    "### üîç Open the workbook in the Azure Portal\n",
    "\n",
    "Open the workbook resource and review the usage analysis to confirm the model routing and other metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
